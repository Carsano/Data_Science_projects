{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Openclassrooms activity - Grid Search\n",
    "The aim is to produce a function for the gridsearch algorithm.\n",
    "Then it will be used to compare to the gridsearch function by Scikitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing,neighbors, model_selection\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "data = pd.read_csv('./TP_Selectionnez_nb_voisins_knn/winequality-white.csv', sep=';')\n",
    "X = data[data.columns[:-1]].values # Not take into account quality\n",
    "y = data['quality'].values\n",
    "y_class = np.where(y<6, 0, 1) # Separate good and bad wines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide set in a training and a test set. \n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y_class, test_size=0.3) \n",
    "\n",
    "# Standardization\n",
    "std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_std = std_scale.transform(X_train)\n",
    "X_test_std = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter : 3\n",
      "{3: 0.7664233576642335, 5: 0.7605839416058394, 7: 0.7474452554744525, 9: 0.7489051094890511, 11: 0.743065693430657, 13: 0.7576642335766424, 15: 0.7562043795620438}\n"
     ]
    }
   ],
   "source": [
    "def add_accur_to_result(result, accur, index):\n",
    "    if index not in result:\n",
    "        result[index] = accur\n",
    "    else:\n",
    "        result[index] += accur\n",
    "    return result\n",
    "def find_max(result):\n",
    "    return max(result, key=result.get)\n",
    "def my_grid_search_two(param_grid,nb_folds):\n",
    "    result = {}\n",
    "    # Create the folds\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=nb_folds)\n",
    "    # On each fold\n",
    "    for k in param_grid['n_neighbors']:\n",
    "        results =[]\n",
    "        for train_index, test_index in kfold.split(X_train_std,y_train):\n",
    "            Xtrain, Xtest = X_train_std[train_index], X_train_std[test_index]\n",
    "            ytrain, ytest = y_train[train_index], y_train[test_index]\n",
    "            accuracy = neighbors.KNeighborsClassifier(k).fit(Xtrain,ytrain).score(Xtest, ytest)\n",
    "            results.append(accuracy)\n",
    "            # Add the accuracy to the dictionnary\n",
    "        result = add_accur_to_result(result, accuracy,k)\n",
    "    best_couple = find_max(result)\n",
    "    print(\"Best hyperparameter : {}\".format(best_couple))\n",
    "    return result\n",
    "\n",
    "\n",
    "param_grid = {'n_neighbors':[3, 5, 7, 9, 11, 13, 15]}\n",
    "nb_folds = 5\n",
    "print(my_grid_search_two(param_grid,nb_folds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code from OC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur(s) hyperparamètres(s) sur le jeu d'entraînement:\n",
      "{'n_neighbors': 3}\n",
      "Résultats de la validation croisée :\n",
      "accuracy = 0.759 (+/-0.019) for {'n_neighbors': 3}\n",
      "accuracy = 0.755 (+/-0.021) for {'n_neighbors': 5}\n",
      "accuracy = 0.753 (+/-0.017) for {'n_neighbors': 7}\n",
      "accuracy = 0.753 (+/-0.008) for {'n_neighbors': 9}\n",
      "accuracy = 0.750 (+/-0.014) for {'n_neighbors': 11}\n",
      "accuracy = 0.757 (+/-0.016) for {'n_neighbors': 13}\n",
      "accuracy = 0.754 (+/-0.019) for {'n_neighbors': 15}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors, metrics\n",
    "param_grid = {'n_neighbors':[3, 5, 7, 9, 11, 13, 15]}\n",
    "score = 'accuracy'\n",
    "\n",
    "# Model kNN creation for hyperparameter research with crossed validation\n",
    "clf = model_selection.GridSearchCV(\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "    param_grid, # hyperparameters\n",
    "    cv=5, # Kfolds nb\n",
    "    scoring=score \n",
    ")\n",
    "\n",
    "# Optimisation of the model\n",
    "clf.fit(X_train_std, y_train)\n",
    "\n",
    "print(\"Meilleur(s) hyperparamètres(s) sur le jeu d'entraînement:\")\n",
    "print(clf.best_params_)\n",
    "\n",
    "print(\"Résultats de la validation croisée :\")\n",
    "for mean, std, params in zip(\n",
    "    clf.cv_results_['mean_test_score'], # Mean\n",
    "    clf.cv_results_['std_test_score'], # Standard deviation\n",
    "    clf.cv_results_['params'] #Hyperparameter value\n",
    "):\n",
    "    print(\"{} = {:.3f} (+/-{:.03f}) for {}\".format(score, mean, std*2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
